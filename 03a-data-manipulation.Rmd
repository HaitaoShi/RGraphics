# 操作 {#manipulate}

```{r,include=FALSE}
library(magrittr) # %>%
```

数据变形，分组统计聚合等，用以作为模型的输入，绘图的对象，操作的数据对象是数据框(data.frame)类型的，而且如果没有特别说明，文中出现的数据集都是 Base R 内置的，第三方 R 包或者来源于网上的数据集都会加以说明。

## 查看 {#show}

```{r,echo=TRUE}
str(iris)
```

```{r,echo=TRUE}
head(iris,5)
tail(iris,5)
```

查看文件前（后）5行

```bash
head -n 5 clientip.csv
tail -n 5 clientip.csv
```

```{r,echo=TRUE}
object.size(iris)
mode(iris)
typeof(iris)
```


```{r,echo=TRUE}
object.size(letters)
object.size(ls)
format(object.size(library), units = "auto")
```


## 清洗 {#clean}

清晰目标是提取字段，整理成数据框的数据存储形式 grep sub gsub

Pattern Matching and Replacement 模式匹配和替换

正则表达式 is ervrywhere，is 高级/hacker's skill 技能

- [正则表达式速查表 -- Python3](https://www.dataquest.io/blog/large_files/python-regular-expressions-cheat-sheet.pdf)
- [Online regex tester and debugger](https://regex101.com/)
- [Regular expression operations](https://docs.python.org/3/library/re.html)
- [Handling Strings with R](http://www.gastonsanchez.com/r4strings/) 字符串处理

R 基础包提供了丰富的字符串处理函数

```{r,eval=FALSE,echo=TRUE}
help.search(keyword = "character", package = "base")
```

R 包维护者

```{r,echo=TRUE}
gsub(" <([^<>]*)>", "", lapply(.packages(TRUE), maintainer) %>%
  unlist()) %>%
  table() %>%
  sort() %>%
  tail(10)
```

我安装 Hadley Wickham 维护的 R 包有 33 个

stringr/stringi

## 重塑 {#reshape}

重复测量数据的变形 Reshape Grouped Data

数据框宽格式 wide 变长格式 long

reshape 支持正则表达式

```{r,echo=TRUE}
str(Indometh)
summary(Indometh)
```
```{r,echo=TRUE}
wide <- reshape(Indometh, v.names = "conc", idvar = "Subject",
                timevar = "time", direction = "wide")
wide[,1:6]
```

长 long 变 wide 宽格式

```{r,echo=TRUE,eval=FALSE}
data(gambia,package = 'geoR')
# Building a "village-level" data frame
ind <- paste("x",gambia[,1], "y", gambia[,2], sep="")
village <- gambia[!duplicated(ind),c(1:2,7:8)]
village$prev <- as.vector(tapply(gambia$pos, ind, mean))
head(village)
```

## 转换 {#transform}

transform 对数据框中的某些列做计算，取对数，将计算的结果单存一列加到数据框中

```{r,echo=TRUE}
transform(iris, scale.sl = (max(Sepal.Length) - Sepal.Length)/(max(Sepal.Length) - min(Sepal.Length))) %>% head(5)
```

::: sidebar
Warning: This is a convenience function intended for use interactively. For programming it is better to use the standard subsetting arithmetic functions, and in particular the non-standard evaluation of argument `transform` can have unanticipated consequences.
:::

## 子集 {#subset}

`subset(x, subset, select, drop = FALSE, ...)` 参数 subset 代表行操作，select 代表列操作

subset() 从数据框中提取部分数据

```{r,echo=TRUE}
subset(iris, Species == "virginica") %>% head(5)
# summary(iris$Sepal.Length)  mean(iris$Sepal.Length)
# 且的逻辑
# subset(iris, Species == "virginica" & Sepal.Length > 5.84333) %>% head(5)
subset(iris, Species == "virginica" & 
         Sepal.Length > mean(Sepal.Length)
       ) %>% head(5)
# 在行的子集范围内
subset(iris, Species %in% c("virginica","versicolor") & 
         Sepal.Length > mean(Sepal.Length)
       ) %>% head(5)
# 在列的子集内 先选中列
subset(iris, Sepal.Length > mean(Sepal.Length), 
       select = c("Sepal.Length","Species")
       ) %>% head(5)
```

高级操作：加入正则表达式筛选

```{r,echo=TRUE}
## sometimes requiring a logical 'subset' argument is a nuisance
nm <- rownames(state.x77)
start_with_M <- nm %in% grep("^M", nm, value = TRUE)
subset(state.x77, start_with_M, Illiteracy:Murder)
# 简化
# subset(state.x77, subset = grepl("^M", rownames(state.x77)), select = Illiteracy:Murder)
# 继续简化
subset(state.x77, grepl("^M", rownames(state.x77)), Illiteracy:Murder)
```

::: sidebar
警告：这是一个为了交互使用打造的便捷函数。对于编程，最好使用标准的子集函数，如 `[`，特别地，参数 `subset` 的非标准计算(non-standard evaluation)[^non-standard-eval]可能带来意想不到的后果。
:::

使用索引 `[` 

```{r,echo=TRUE}
iris[iris$Species == "virginica", ] %>% head(5)
iris[iris$Species == "virginica" &  
       iris$Sepal.Length > mean(iris$Sepal.Length), 
     ] %>% head(5)

iris[iris$Species == "virginica" &  
       iris$Sepal.Length > mean(iris$Sepal.Length), 
     c("Sepal.Length","Species")] %>% head(5)
```

[^non-standard-eval]: Thomas Lumley (2003) Standard nonstandard evaluation rules. https://developer.r-project.org/nonstandard-eval.pdf

## 排序 {#order}

在数据框内，根据(order)某一列或几列对行进行排序(sort)，根据鸢尾花(iris)的类别(Species)对萼片(sepal)的长度进行排序，其余的列随之变化

```{r,echo=TRUE}
# 对萼片的长度排序
iris[order(iris$Species,iris$Sepal.Length),] %>% head(5)
# 对花瓣的长度排序
iris[order(iris$Species,iris$Petal.Length),] %>% head(5)
# 先对花瓣的宽度排序，再对花瓣的长度排序
iris[order(iris$Petal.Width,iris$Petal.Length),] %>% head(5)
```

sort 排序

## 拆分 {#split}

```{r,echo=TRUE}
## Notice that assignment form is not used since a variable is being added
g <- airquality$Month
l <- split(airquality, g) # 分组
l <- lapply(l, transform, Oz.Z = scale(Ozone)) # 计算
aq2 <- unsplit(l, g) # 合并
head(aq2)
```

```{r,echo=TRUE}
with(aq2, tapply(Oz.Z,  Month, sd, na.rm = TRUE))
```

以 iris 数据集为例

```{r,echo=TRUE}
g <- iris$Species
l <- split(iris, g) # 分组
l <- lapply(l, transform, scale.sl = scale(Sepal.Length)) # 计算
unsplit(l, g) %>% head(5) # 合并
```

## 合并 {#merge}

merge 合并两个数据框

cbind
rbind

left join
right join

## 聚合 {#aggregate}

主要是分组统计

```{r,echo=TRUE}
apropos("apply")
```

```{r,echo=TRUE}
# 分组求和 colSums colMeans max
unique(iris$Species)
# 分类求和
# colSums(iris[iris$Species == "setosa", -5])
# colSums(iris[iris$Species == "virginica", -5])
colSums(iris[iris$Species == "versicolor", -5])
# apply(iris[iris$Species == "setosa", -5], 2, sum)
# apply(iris[iris$Species == "setosa", -5], 2, mean)
# apply(iris[iris$Species == "setosa", -5], 2, min)
# apply(iris[iris$Species == "setosa", -5], 2, max)
apply(iris[iris$Species == "setosa", -5], 2, quantile)
```

aggregate: Compute Summary Statistics of Data Subsets

```{r,echo=TRUE}
# 按分类变量 Species 分组求和
# aggregate(subset(iris, select = -Species), by = list(iris[, "Species"]), FUN = sum)
aggregate(iris[, -5], list(iris[, 5]), sum)
# 先确定位置，假设有很多分类变量
ind <- which("Species" == colnames(iris))
# 分组统计
aggregate(iris[, -ind], list(iris[, ind]), sum)
```

按照 Species 划分的类别，分组计算，使用公式表示形式，右边一定是分类变量，否则会报错误或者警告，输出奇怪的结果，请读者尝试运行`aggregate(Species ~ Sepal.Length, data = iris, mean)`。公式法表示分组计算，`~` 左手边可以做加 `+` 减 `-` 乘 `*` 除 `/` 取余 `%%` 等数学运算。下面以数据集 iris 为例，只对 Sepal.Length 按 Species 分组计算

```{r,echo=TRUE}
aggregate(Sepal.Length ~ Species, data = iris, mean)
```

与上述分组统计结果一样的命令，在大数据集上， 与 aggregate 相比，tapply 要快很多，by 是 tapply 的包裹，处理速度差不多。读者可以构造伪随机数据集验证。

```{r,echo=TRUE}
tapply(iris$Sepal.Length, list(iris$Species), mean)
by(iris$Sepal.Length, iris$Species, mean)
```

对所有变量按 Species 分组计算 

```{r,echo=TRUE}
aggregate(. ~ Species, data = iris, mean)
```

对变量 Sepal.Length 和 Sepal.Width 求和后，按 Species 分组计算

```{r,echo=TRUE}
aggregate(Sepal.Length + Sepal.Width ~ Species, data = iris, mean)
```

对多个分类变量做分组计算，在数据集 ChickWeight 中 Chick和Diet都是数字编码的分类变量，其中 Chick 是有序的因子变量，Diet 是无序的因子变量，而 Time 是数值型的变量，表示小鸡出生的天数。

```{r,echo=TRUE}
# 查看数据
str(ChickWeight)
```

查看数据集ChickWeight的前几行

```{r, out.lines=6, echo=TRUE}
# head(ChickWeight)
ChickWeight
```

对于数据集ChickWeight中的有序变量Chick，aggregate 会按照既定顺序返回分组计算的结果

```{r,echo=TRUE, out.lines=6}
aggregate(weight ~ Chick, data = ChickWeight, mean)
aggregate(weight ~ Diet, data = ChickWeight, mean)
```

分类变量没有用数字编码，以 CO2 数据集为例，该数据集描述草植对二氧化碳的吸收情况，Plant 是具有12个水平的有序的因子变量，Type表示植物的源头分别是魁北克(Quebec)和密西西比(Mississippi)，Treatment表示冷却(chilled)和不冷却(nonchilled)两种处理方式，conc表示周围环境中二氧化碳的浓度，uptake表示植物吸收二氧化碳的速率。

```{r,echo=TRUE}
# 查看数据集
head(CO2)
str(CO2)
```

对单个变量分组统计

```{r,echo=TRUE}
aggregate(uptake ~ Plant, data = CO2, mean)
aggregate(uptake ~ Type, data = CO2, mean)
aggregate(uptake ~ Treatment, data = CO2, mean)
```

对多个变量分组统计，查看二氧化碳吸收速率uptake随类型Type和处理方式Treatment

```{r,echo=TRUE}
aggregate(uptake ~ Type + Treatment, data = CO2, mean)
tapply(CO2$uptake, list(CO2$Type,CO2$Treatment), mean)
by(CO2$uptake,list(CO2$Type,CO2$Treatment), mean)
```

在这个例子中 tapply 和 by 的输出结果的表示形式不一样，aggregate 返回一个 data.frame 数据框，tapply 返回一个表格 table，by 返回特殊的数据类型 by。

Function `by` is an object-oriented wrapper for `tapply` applied to data frames. 

```{r,echo=TRUE}
# 分组求和
# by(iris[, 1], INDICES = list(iris$Species), FUN = sum)
# by(iris[, 2], INDICES = list(iris$Species), FUN = sum)
by(iris[, 3], INDICES = list(iris$Species), FUN = sum)
by(iris[1:3], INDICES = list(iris$Species), FUN = sum)
by(iris[1:3], INDICES = list(iris$Species), FUN = summary)
by(iris, INDICES = list(iris$Species), FUN = summary)
```

Group Averages Over Level Combinations of Factors 分组平均

```{r,echo=TRUE}
str(warpbreaks)
ave(warpbreaks$breaks, warpbreaks$wool)
warpbreaks %>% head(5)
with(warpbreaks, ave(breaks, tension, FUN = function(x) mean(x, trim = 0.1)))
# 分组求和
with(warpbreaks, ave(breaks, tension, FUN = function(x) sum(x)))
# 分组求和
with(iris,ave(Sepal.Length,Species, FUN = function(x) sum(x)))
```


## 表格 {#cross-table}

> 介绍操作表格的 table, addmargins, prop.table, xtabs, margin.table, ftabe 等函数

table 多个分类变量分组计数统计 

- 介绍 warpbreaks 和 airquality 纽约空气质量监测数据集 二维的数据框
- UCBAdmissions 1973 年加州大学伯克利分校的院系录取数据集 3维的列联表
- Titanic 4维的列联表数据 泰坦尼克号幸存者数据集

```{r,echo=TRUE}
with(warpbreaks, table(wool, tension))
```

以 iris 数据集为例，table 的第一个参数是自己制造的第二个分类变量，原始分类变量是 Species

```{r,echo=TRUE}
with(iris, table(Sepal.check = Sepal.Length > 7, Species))
with(iris, table(Sepal.check = Sepal.Length > mean(Sepal.Length), Species))
```

以 airquality 数据集为例，看看月份中臭氧含量比较高的几天

```{r,echo=TRUE}
aiq.tab <- with(airquality, table(Oz.high = Ozone > 80, Month))
aiq.tab
```

对表格按行和列求和，即求表格的边际，查看总体情况

```{r,echo=TRUE}
addmargins(aiq.tab, 1:2)
```

臭氧含量超 80 的天数在每个月的占比，`addmargins` 的第二个参数 1 表示对列求和

```{r,echo=TRUE}
aiq.prop <- prop.table(aiq.tab, 2)
aiq.prop
aiq.marprop <- addmargins(aiq.prop, 1)
aiq.marprop
```

转换成百分比，将小数四舍五入转化为百分数，保留两位小数点

```{r,echo=TRUE}
round(100 * aiq.marprop, 2)
```

```{r,eval=FALSE}
pairs(airquality, panel = panel.smooth, main = "airquality data")
```

以 UCBAdmissions 数据集为例，使用 `xtabs` 函数把数据组织成列联表，先查看数据的内容

```{r,out.lines=6,echo=TRUE}
UCBAdmissions
UCBA2DF <- as.data.frame(UCBAdmissions)
UCBA2DF
```

接着将 `UCBA2DF` 数据集转化为表格的形式

```{r,echo=TRUE}
UCBA2DF.tab <- xtabs(Freq ~ Gender + Admit + Dept, data = UCBA2DF)
ftable(UCBA2DF.tab)
```

将录取性别和院系进行对比

```{r,echo=TRUE}
prop.table(margin.table(UCBA2DF.tab, c(1, 3)), 1)
```

男生倾向于申请院系 A 和 B，女生倾向于申请院系 C 到 F，院系 A 和 B 是最容易录取的。

## `[[` {#quote}

which 与引用 `[` 性能比较，在区间 $[0,1]$ 上生成 10 万个服从均匀分布的随机数，随机抽取其中$\frac{1}{4}$。

```{r,echo=TRUE}
n = 100000
x = runif(n)
i = logical(n)
i[sample(n, n/4)] = TRUE
microbenchmark::microbenchmark(x[i], x[which(i)], times = 1000)
```

with 和 within

## 其它 {#others}

成对的数据操作

list unlist 
stack unstack 
class unclass
attach detach

[^apply-family]: https://stackoverflow.com/questions/3505701/grouping-functions-tapply-by-aggregate-and-the-apply-family
