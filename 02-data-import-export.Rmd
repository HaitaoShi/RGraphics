# 数据搬运工 {#data-porter}

导入数据与导出数据，各种数据格式，数据库

## 读写数据集 {#read-write-data}

```{r,echo=TRUE}
apropos("^read.")
apropos("^write.")
```

### `scan` {#scan}

### `read.csv` 与 `write.csv` {#read-write-csv}

`read.csv2` 与 `write.csv2` 

### `read.table` 与 `write.table` {#read-write-table}

变量名是不允许以下划线开头的，同样在数据框里，列名也不推荐使用下划线开头。默认情况下，`read.table` 都会通过参数 `check.names` 检查列名的有效性，该参数实际调用了函数 `make.names` 去检查。如果想尽量保持数据集原来的样子可以设置参数 `check.names = FALSE, stringsAsFactors = FALSE`。 默认情形下，`read.table` 还会将字符串转化为因子变量，这是 R 的历史原因，作为一门统计学家的必备语言，在统计模型中，字符常用来描述类别，而类别变量在 R 环境中常用因子类型来表示，而且大量内置的统计模型也是将它们视为因子变量，如 lm 、glm 等

```{r,echo=TRUE}
dat1 = read.table(header = TRUE, check.names = TRUE, text = "
_a _b _c
1 2 a1
3 4 a2
")
dat1
dat2 = read.table(header = TRUE, check.names = FALSE, text = "
_a _b _c
1 2 a1
3 4 a2
")
dat2
dat3 = read.table(header = TRUE, check.names = FALSE, stringsAsFactors = FALSE, text = "
_a _b _c
1 2 a1
3 4 a2
")
dat3
```

### `readLines` 与 `writeLines` {#read-write-lines}

让我们折腾一波，读进来又写出去

```{r,echo=TRUE}
writeLines(readLines("latex/TeXLive.pkgs"),"latex/TeXLive.pkgs")
```



### `readRDS` 与 `saveRDS` {#read-save-rds}

序列化数据操作，Mark Klik 开发的 [fst](https://github.com/fstpackage/fst) 和 [Travers Ching](https://travers.im/) 开发的 [qs](https://github.com/traversc/qs)

Table: (\#tab:fst-vs-others) fst 序列化数据框对象性能比较 BaseR、 data.table 和 feather [^fst-performance]

| Method         | Format  | Time (ms) | Size (MB) | Speed (MB/s) | N       |
| :------------- | :------ | :-------- | :-------- | :----------- | :------ |
| readRDS        | bin     | 1577      | 1000      | 633          | 112     |
| saveRDS        | bin     | 2042      | 1000      | 489          | 112     |
| fread          | csv     | 2925      | 1038      | 410          | 232     |
| fwrite         | csv     | 2790      | 1038      | 358          | 241     |
| read\_feather  | bin     | 3950      | 813       | 253          | 112     |
| write\_feather | bin     | 1820      | 813       | 549          | 112     |
| **read\_fst**  | **bin** | **457**   | **303**   | **2184**     | **282** |
| **write\_fst** | **bin** | **314**   | **303**   | **3180**     | **291** |

目前比较好的是 qs 和 fst 包 


[^fst-performance]: https://www.fstpackage.org/ 

### `read.ftable` 与 `write.ftable` {#read-write-ftable}


### `readBin` 与 `writeBin` {#read-write-bin}


### `readChar` 与 `writeChar` {#read-write-char}


### `read.dcf` 与 `write.dcf` {#read-write-dcf}


### `readClipboard` 与 `writeClipboard` {#read-write-clipboard}


### `read.socket` 与 `write.socket` {#read-write-socket}

### `load` 与 `save` {#load-save}



导入数据，也叫读入数据，读取数据，读入到 R 环境中，从磁盘上的文件，变成存储在R环境中的数据对象

写入压缩格式文件


`capture.output` 参数为表达式

`with` 与 `attach`
`sink`


```r
sink("sink-examp.txt")
i <- 1:10
outer(i, i, "*")
sink()
```

只将 `outer` 的结果保存到 `sink-examp.txt` 文件



### `source` 与 `dump` {#source-dump}

`dump` 保存数据对象 iris 到文件 `iris.txt`，文件内容是 R 命令，可把`iris.txt`看作代码文档执行，dput 保存数据对象内容到文件`iris.dat`，文件中不包含变量名 iris。注意到 `dump` 输入是一个字符串，而 `dput` 要求输入数据对象的名称，`source` 函数与 `dump` 对应，而 `dget` 与 `dput`对应。 

```{r,eval=FALSE,echo=TRUE}
data(iris)
dump('iris', file = 'iris.txt') 
source(file = 'iris.txt')
```

### `dget` 与 `dput` {#dget-dput}

```{r,eval=FALSE,echo=TRUE}
dput(iris, file = 'iris.dat')
iris <- dget(file = 'iris.dat')
```


读取 SPSS Matlab SAS 等软件生成的数据文件

戏称 [rio](https://github.com/leeper/rio) 包是数据导入导出 Input/Output  的瑞士军刀

### jsonlite 与 yaml

jsonlite 包读取 `*.json` 格式的文件，`jsonlite::write_json` 函数将 R对象保存为 JSON 文件，`jsonlite::fromJSON` 将 json 字符串或文件转化为 R 对象，`jsonlite::toJSON` 函数正好与之相反

```{r,echo=TRUE,eval=FALSE}
library(jsonlite)
jsonlite::read_json(path = "path/to/filename.json")
```

yaml 包读取 `*.yml` 格式文件，返回一个列表，`yaml::write_yaml` 函数将 R 对象写入 yaml 格式 

```{r,echo=TRUE}
library(yaml)
yaml::read_yaml(file = '_bookdown.yml')
```

yaml 和 json 格式互转

## 读写数据库 {#read-write-database}

[Hands-On Programming with R](https://rstudio-education.github.io/hopr) 数据读写章节[^dataio]

[^dataio]: https://rstudio-education.github.io/hopr/dataio.html

### ODBC 与 DBI

制作一个表格，左边数据库右边 R 接口，都包含链接，如表 \@ref(tab:dbi) 所示

```{r dbi}
db2r <- data.frame(
  db = c("MySQL", "SQLite", "PostgreSQL", "MariaDB"),
  db_urls = c(
    "https://www.mysql.com/",
    "https://www.sqlite.org",
    "https://www.postgresql.org/",
    "https://mariadb.org/"),
  dbi = c("RMySQL", "RSQLite", "RPostgres", "RMariaDB"),
  dbi_urls = c(
    "https://github.com/r-dbi/RMySQL",
    "https://github.com/r-dbi/RSQLite",
    "https://github.com/r-dbi/RPostgres",
    "https://github.com/r-dbi/RMariaDB"
  )
)
# db <-  paste0("[", db2r$db, "](", db2r$db_urls, ")")
# dbi <- paste0("[", db2r$dbi, "](", db2r$dbi_urls, ")")
knitr::kable(db2r, col.names = c("数据库","官网","R接口","开发仓"), caption = "数据库接口")
```

### PostgreSQL

[odbc](https://github.com/r-dbi/odbc) 可以支持很多数据库，下面以连接 [PostgreSQL](https://www.postgresql.org/) 数据库为例介绍其过程

在 MacOS 上安装

```bash
# 安装 unixODBC 库
brew install unixodbc
# 安装 PostgreSQL
brew install psqlodbc
```

在 Ubuntu 上配置

```bash
# Install the unixODBC library
sudo apt-get install unixodbc unixodbc-dev
# PostgreSQL ODBC ODBC Drivers
sudo apt-get install odbc-postgresql
```

建立连接

```{r,echo=TRUE,eval=FALSE}
library(DBI)
con <- dbConnect(odbc::odbc(),
  driver = "PostgreSQL Driver",
  database = "test_db",
  uid = "postgres",
  pwd = "password",
  host = "localhost",
  port = 5432)
# host 可以是云端的地址也可以是本地局域网IP地址，
# 例如"192.168.1.200"这样的。
# 列出数据库中的所有表
dbListTables(con)
```

参考 <https://brucezhaor.github.io/blog/2016/08/04/batch-process-txt-to-mysql/>

### ClickHouse

对系统的要求是 System requirements: Linux, x86_64 with SSE 4.2.

```{bash,eval=F}
sudo apt-get install dirmngr    # optional
sudo apt-key adv --keyserver keyserver.ubuntu.com --recv E0C56BD4    # optional

echo "deb http://repo.yandex.ru/clickhouse/deb/stable/ main/" | sudo tee /etc/apt/sources.list.d/clickhouse.list
sudo apt-get update

sudo apt-get install -y clickhouse-server clickhouse-client
# 启动服务
sudo service clickhouse-server start
# 进入客户端
clickhouse-client
```

[ClickHouse 中文用户手册](https://clickhouse.yandex/docs/zh/) 和新浪高鹏在北京 [ClickHouse社区分享会](https://clickhouse.yandex/blog/en/clickhouse-community-meetup-in-beijing-on-january-27-2018) 上给的报告 [MySQL DBA解锁数据分析的新姿势-ClickHouse](https://yandex.github.io/clickhouse-presentations/meetup12/power_your_data.pdf) 

开源社区对 ClickHouse 提供了很多语言的支持，比如 R 语言接口有 [RClickhouse](https://github.com/IMSMWU/RClickhouse) 和 [clickhouse-r](https://github.com/hannesmuehleisen/clickhouse-r)，其它接口请看 [官方文档链接](https://clickhouse.yandex/docs/zh/interfaces/third-party/client_libraries/)

由于 clickhouse-r 还在开发中，从未提交到 CRAN，提供的功能也相对有限，这里我们推荐使用 RClickhouse，首先安装 RClickhouse

```{r,eval=FALSE,echo=TRUE}
# 安装 CRAN 版本
install.packages("RClickhouse")
# 安装Github上的开发版
devtools::install_github("IMSMWU/RClickhouse")
```

建立数据库的连接，离不开 `dbConnect` 函数，它提供的 `config_paths` 参数用来指定配置文件 `RClickhouse.yaml` 的路径，在该文件中指定一系列的参数值 `host, port, db, user, password, compression`

```yaml
host: example-db.com
port: 1111
```

如果没有手动配置，会使用默认的参数配置 `host="localhost", port = 9000, db = "default", user = "default", password = "", compression = "lz4"`

RClickHouse 提供部分 dplyr 式的数据操作

```{r,eval=identical(.Platform$OS.type,'unix'),echo=TRUE}
library(RClickhouse)
# 建立数据库连接
con <- DBI::dbConnect(RClickhouse::clickhouse(), config_paths = "~/.R/RClickhouse.yaml")

# 往 ClickHouse 中写入数据
DBI::dbWriteTable(con, "mtcars", mtcars, overwrite=TRUE)

# 列出 ClickHouse 中存放的表
dbListTables(con)
dbListFields(con, "mtcars")

# 查询数据
library(dplyr, warn.conflicts = FALSE)

# 按变量 cyl 分组对 mpg 求和
tbl(con, "mtcars") %>% 
  group_by(cyl) %>% 
  summarise(smpg=sum(mpg))

# 等价于
aggregate(mpg ~ cyl, data = mtcars, sum)

# 先筛选出 cyl = 8 并且 vs = 0 的数据，然后按 am 分组，最后对 qsec 求平均值
tbl(con, "mtcars") %>% 
  filter(cyl == 8, vs == 0) %>% 
  group_by(am) %>% 
  summarise(mean(qsec))

# 等价于
aggregate(qsec ~ am, data = mtcars, mean, subset = cyl == 8 & vs == 0)

# 不使用数据库的时候一定记得关闭数据库的连接
dbDisconnect(con)
```

你当然可以继续使用 SQL 语句做查询，而不使用 dplyr 提供的现代化的管道操作语法

```{r,eval=FALSE,echo=TRUE}
# 传递查询语句
DBI::dbGetQuery(con, "SELECT
                             vs
                            ,COUNT(*) AS 'number of cases'
                            ,AVG(qsec) AS 'average qsec'
                      FROM mtcars
                      GROUP BY vs")

# 保存查询结果
res <- DBI::dbGetQuery(con, "SELECT (*)
                             FROM mtcars
                             WHERE am = 1")

# 如果数据集比较小，可以将 ClickHouse 的整张表读进内存，但是对于大数据集，只有使用远程服务器可以获得更好的性能
mtcars <- dbReadTable(con, mtcars)

# 不使用数据库的时候一定记得关闭数据库的连接
dbDisconnect(con)
```

还有 RClickhouse 使用 SQL 查询的时候，同样支持 ClickHouse 的内置函数

```{r,eval=FALSE,echo=TRUE}
# 查看 ClickHouse 中所有的数据库名称
DBI::dbGetQuery(con, "SHOW DATABASES")

# 获取 ClickHouse 中表 mtcars 的变量名和类型
DBI::dbGetQuery(con, "DESCRIBE TABLE mtcars")

# Compact CASE - WHEN - THEN conditionals
DBI::dbGetQuery(con, "SELECT multiIf(am='1', 'automatic', 'manual') AS 'transmission'
                            ,multiIf(vs='1', 'straight', 'V-shaped') AS 'engine' 
                      FROM mtcars")

# 不使用数据库的时候一定记得关闭数据库的连接
dbDisconnect(con)
```


